{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Rating Predictor for Amazon\n",
    "by Allen Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Amazon is one of the largest e-commerce companies and are one of the big five of the US information technology industry. Amazon offers a huge variety of products in a multitude of categories. Their products are defined by 5 star ratings and reviews and a large objective of this project was to identify and label customer satisfaction among purchasers of amazon products. I have created an algorithm that sorts text data into three categories of ratings: (High: 4-5 stars, Medium: 3 stars, Low: 1-2 stars). The reasoning for sorting into three categories is that a consumer's rating of a 4 star review is hardly distinguishable from a 5 star review for a computer let alone a human and the same goes with a 1 or a 2 star review. The model takes in text data and outputs an overall satisfaction grade from the customer: High, Medium, or Low.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Amazon Products](amazon.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data comes from a dataset on Kaggle.com that was published by Datafini. Datafini has a product database of a number of Amazon products that range from the Kindle Fire to Amazon Essentials. The dataset comes with 24 columns of information and 28,332 reviews and ratings and other information such as product ID, product category. To view the dataset and the Datafini homepage click on the links below:\n",
    "\n",
    "* [Datafini](https://datafiniti.co/)\n",
    "\n",
    "\n",
    "* [Kaggle](https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products?select=Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this type of project, it is imperative to properly sample the data, vectorize the text data, and apply the TFIDF transformer which is term frequency-inverse document frequency. This is a statistical method for retrieving keywords from documents and we're going to use this method for keyword frequency. The formula for TFIDF is shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tfidf](tfidf1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's important is that the TFIDF transformer turns raw text data into word frequency numerical data that can be fitted to different models.\n",
    "\n",
    "After the TFIDF transformer is applied, the data is run through different algorithms of choice: Logistic Regression,  Mulitnomial Naive-Bayes, Random Forest, Linear Support Vector Classifier, and XGBoost. \n",
    "Logistic Regression is a mostly used as a binary classifier and it is modeled by a sigmoid function. Multinomial Naive-Bayes is a classifier used for classification often used for discrete features and in our case, word count. It might seem like the most ideal algorithm to be used for this project. Random forest is a conglomeration of decision trees and is a relatively good algorithm for most scenarios. It also automatically balances datasets with imbalanced categories. Linear Support Vector Classifier is an algorithm that draws a hyperplane separating datapoints into different classes. XGBoost is gradient boosting classifier and that is a that new models are added in order to account for the errors learned by previous models. It is still not clear what algorithm to use but I'm leaning towards random forests, Multinomial NB, and XGBoost since all are reliable algorithms that can handle a wide variety of data. XGBoost proves to be the most reliable and accurate model in Kaggle competitions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just from looking at the dataset, there seems to be a couple problems to begin with. There are two columns with nearly all missing values: 'reviews.id' and 'reviews.didPurchase'. Those columns are not going to be useful at all. I decided to drop those columns in order to clean the dataset. Another problem was that all the date time objects need to be converted to the datetime format if we wanted to conduct some data analysis or some feature engineering on those columns. I converted three columns to datetime objects 'reviews.date','dateAdded', and 'dateUpdated'. I called a value_counts() on the 'ratings.review' column and discovered that the dataset was heavily imbalanced so eventually later on in the machine learning process, I downsampled the number of 5 rating reviews and 4 rating reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ratinghistogram](download.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to examine the most popular products and the products with the most reviews. The most reviewed products were electronics and coming in at a close second is Health and Beauty. The most popular products were the Amazon Triple A and double A batteries and the second most popular Amazon products were the Fire HD 8 Tablet and the Kids Tablet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Popular Categories    |  Most Popular Products\n",
    ":-------------------------:|:-------------------------:\n",
    "![](eda1.png)  |  ![](eda4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then created a scatterplot showing the review lengths in respect to the review ratings. From the plot it shows a positive correlation between the review rating and the review length but mostly long review in the 4 star category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ratinghistogram](eda3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also I realized that it is extremely difficult to distinguish between 4 or 5 stars or 1 or 2 stars so decided to create three classes of ratings: 'High', 'Medium', and 'Low'. High consists of 4 or 5 stars, Medium consists of 3 stars, and Low consists of 1 or 2 stars. Now the data is ready to be utilized for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Algorithms and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create and fit a machine learning model out of text data we need to apply the count vectorizer to the review text column of the dataset. After applying the count vectorizer, I looked at the most popular words and bigrams that are common amongst the reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ratinghistogram](eda5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a wordcloud for the most common words in the reviews.text column of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Rating   |  Medium Rating   | Low Rating\n",
    ":-------------------------:|:-------------------------:|:-------------------------:\n",
    "![](wordcloud3.png)  |  ![](wordcloud2.png) | ![](wordcloud1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the earlier bar graph of the number of 5 star reviews, I realized the dataset was heavily imbalanced. I needed to downsample the nubmer of 5 star ratings and 4 star ratings as well. I realize this is a problem because Amazon products are usually reliable considering that the products are made from Amazon themselves. I downsampled the number of 5 star reviews to a 2:1 ratio in comparison with the other ratings. Even though it is still imbalanced, it is a fair number to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then called a train_test_split on the dataset, splitting the data 80/20 training and testing. I then called a function that ran the data through every single algorithm listed above. For the scoring metric, I decided accuracy was not the move. Accuracy only works on balanced datasets. For the Amazon dataset, it is still somewhat imbalanced after the downsampling as there are twice as many 5 star reviews as any other reviews. Therefore, I decided to use f1 score, specifically f1 micro as it accounts for class imbalances. F1 score is a formula that is a combination of precision and recall and precision is a metric that \n",
    "prioritizes minimizing false positives and recall prioritizes minimizing false negatives. Since neither are that drastic to the integrity to the model results, I decided to go with a f1 score metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ratinghistogram](eda6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model results were Linear Support Vector Classifiers and the XGB Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier is a highly reliable and efficient algorithm since it is a form of gradient boosting. I decided to tune the hyperparameters for the XGBoost Classifier and to see if I could improve that model's results. I decided to conduct a Random Search. I decided on random search because a grid search will take too much CPU capacity and will inefficient in terms of computation time and CPU usage. Random search also provides near similar results as grid search with significantly less computational power. The random search somehow gave us a worse score than the default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ratinghistogram](classreport1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report of random searched XGBoost model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ratinghistogram](xgboostparams.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ratinghistogram](classreport2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report of Linear SVC model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ratinghistogram](classreport3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After consideration, I realized it was better to use ROC-AUC score as the scoring metric because it shows individual probabilities of data being designated to a specific class rather than using the 50% threshold of the f1-score. It is a better scoring metric for our type of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ratinghistogram](rocaucscore.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite having run extra computations and random searching parameters for XGBoost, Linear SVC still had the highest ROC-AUC score which is the metric I'm going to use to evaluate my model. Therefore, Linear SVC is the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ratinghistogram](finalmodel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
